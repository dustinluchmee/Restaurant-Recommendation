{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restaurant Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project was done to get experience building recommendation systems. This project could also be adapted and applied to hotels, travel services, and car recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import needed packages\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import squarify\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import and view dataframe. I used the TripAdvisor Restaurant Recommendation dataset from Kaggle. \n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"TripAdvisor_RestauarantRecommendation.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The phone number, URL, and menu link aren't needed. We can remove these from the dataframe. \n",
    "df.drop(['Contact Number', 'Trip_advisor Url', 'Street Address', 'Menu'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Null values can mess up preprocessing and analysis. This step allows us to get rid of null values. \n",
    "df.dropna(inplace=True, axis=0)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The review ratings are within a string. This allows us to extract numbers from review columns\n",
    "df['Reviews'] = [r.split()[0] for r in df.Reviews]\n",
    "\n",
    "#remove whitespace within review columns\n",
    "df['Reviews'] = df['Reviews'].str.lstrip()\n",
    "df['Reviews'] = df['Reviews'].str.rstrip()\n",
    "\n",
    "#convert review data to float and number of reviews to integers\n",
    "df['Reviews'] = df['Reviews'].astype('float')\n",
    "df['No of Reviews'] = [n.split()[0].replace(',', '') for n in df['No of Reviews']]\n",
    "df['No of Reviews'] = df['No of Reviews'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting a mean rating allows for comparison against all other restaurants in the data set \n",
    "restaurants = list(df['Name'].unique())\n",
    "df['Mean Rating'] = 0\n",
    "for i in range(len(restaurants)):\n",
    "    df['Mean Rating'][df['Name'] == restaurants[i]] = df['Reviews'][df['Name'] == restaurants[i]].mean()   \n",
    "#Scaling the mean rating values\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range = (1,5))\n",
    "df[['Mean Rating']] = scaler.fit_transform(df[['Mean Rating']]).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can convert the price range to string categories. This will come in handy for EDA and recommending. \n",
    "df['Price_Range'] = ['Cheap' if p == '$' else 'Moderate' if p == '$$ - $$$' else 'Expensive' for p in df.Price_Range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll want to categorize restaurants by their city and state in our analysis, so let's extract that information from the Location column.\n",
    "df['City'] = [c.split(',')[0].strip() for c in df.Location]\n",
    "df['State'] = [s.split(',')[1][:3].strip() if len(s.split(',')) == 2 else s.split(',')[2][:3].strip() for s in df.Location]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check value counts of states to see any anomalies in the representation\n",
    "df['State'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['State'] == \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can drop PA, OR, and the Canadian province as these states do not have as many restaurant entries as the other states. \n",
    "df.drop(df[(df['State'] == 'PA') | (df['State'] == 'OR') | (df['State'] == '')].index, inplace=True)\n",
    "df.drop('Location', axis=1, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Cleaning up the comments data. We'll use this data to see how comments may be helpful in recommending a restaurant. \n",
    "\n",
    "## Lower casing the text\n",
    "df[\"Comments\"] = df[\"Comments\"].str.lower()\n",
    "\n",
    "## Removal of Puctuations\n",
    "import string\n",
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"custom function to remove the punctuation\"\"\"\n",
    "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "\n",
    "df[\"Comments\"] = df[\"Comments\"].apply(lambda text: remove_punctuation(text))\n",
    "\n",
    "# Removal of Stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "df[\"Comments\"] = df[\"Comments\"].apply(lambda text: remove_stopwords(text))\n",
    "\n",
    "#Cleaning URLs\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "df[\"Comments\"] = df[\"Comments\"].apply(lambda text: remove_urls(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the types of restaurants\n",
    "counts = df[\"Type\"].value_counts()[:10] \n",
    "p = counts.sort_values().plot.barh(figsize=(8,5), fontsize=18) \n",
    "p.set_xlabel(\"Number of Restaurants\",fontsize=18) \n",
    "p.set_ylabel(\"Restaurant Types\",fontsize=18)\n",
    "p.set_title(\"Types of Restaurants\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total restaurants by state\n",
    "ax = df['State'].value_counts().plot(kind='bar', figsize=(10,5), color='b')\n",
    "ax.set_xlabel('No of Restaurants')\n",
    "ax.set_ylabel('State')\n",
    "ax.set_title('No of Restaurants by State')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total restaurants by city\n",
    "ax = df['City'].value_counts()[:20].plot(kind='barh', figsize=(10,8), color='m')\n",
    "ax.set_xlabel('No of Restaurants')\n",
    "ax.set_ylabel('State')\n",
    "ax.set_title('No of Restaurants by City')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restaurant types\n",
    "#The categories of restaurants are all lumped together. People may find it more helpful when searching for a restauant to just use one restaurant type.\n",
    "\n",
    "\n",
    "# Create set of all unique Types\n",
    "types = []\n",
    "for i in df.Type:\n",
    "    for s in i.split(','):\n",
    "        types.append(s.strip())\n",
    "types = set(types)\n",
    "\n",
    "# Create Dict of Types + Frequency\n",
    "type_count = {}\n",
    "for i in df.Type:\n",
    "    for s in i.split(','):\n",
    "        if s.strip() in type_count.keys():\n",
    "            type_count[s.strip()] += 1\n",
    "        else:\n",
    "            type_count[s.strip()] = 1\n",
    "            \n",
    "#Convert Type_count dict into DataFrame\n",
    "df_type = pd.DataFrame(type_count, index = [0])\n",
    "df_type = df_type.transpose()\n",
    "df_type.columns = ['No of Restaurants']\n",
    "df_type.sort_values(by=['No of Restaurants'], ascending=False, inplace = True)\n",
    "\n",
    "# Create DataFrame with top 20 types + the total sum of all other types\n",
    "df_type_top = df_type[:20]\n",
    "other = pd.DataFrame({'No of Restaurants' : sum(df_type['No of Restaurants'][20:])}, index=[0])\n",
    "other.rename(index={0:'Other'}, inplace=True)\n",
    "df_type_top = pd.concat([df_type_top, other], axis=0)\n",
    "df_type_top.sort_values(by=['No of Restaurants'], ascending=False, inplace = True)\n",
    "df_type_top\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 20 Types on Treemap\n",
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "sns.set_style(style=\"darkgrid\") # set seaborn plot style\n",
    "ax = squarify.plot(sizes=df_type_top['No of Restaurants'], label=df_type_top.index, alpha=0.6).set(title='Top 20 Most Common Restaurant Types')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ranking Type by Average Review Score\n",
    "typeAverageReview = {}\n",
    "for t in types:\n",
    "    if len(df[df['Type'].str.contains(t) == True]) >=  30:\n",
    "        typeAverageReview[t] = df[df['Type'].str.contains(t) == True]['Reviews'].mean()\n",
    "        \n",
    "        \n",
    "pd.Series(typeAverageReview).sort_values(ascending=False).plot(kind='barh', figsize=(10,12), bottom=[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 of the top 10 best rated restaurant types where foriegn food. On the other hand, only 3 of the lowest rated types were foreign with the others being generic types like Bar or Pub, or explicitly American such as Southwestern, Barbecue, or American.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Review Score by Price Range\n",
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "ax = sns.violinplot(data=df, x='Reviews', y='Price_Range', order=['Expensive', 'Moderate', 'Cheap'])\n",
    "ax.set_title('Review Scores by Price Range')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The violin plot reinforces that 4.5 is the most common rating. It's the median rating for all 3 Price Ranges. It's interesting that cheap restaurants contain a slightly higher distribution of 5 ratings than the other Price Ranges. Perhaps this is because these restaurants are more accessible to a wider range of customers. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restaurant recommendation system based on the content in the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA- Word Frequency Distribution\n",
    "\n",
    "\n",
    "def get_top_words(column, top_nu_of_words, nu_of_word):\n",
    "    vec = CountVectorizer(ngram_range= nu_of_word, stop_words='english')\n",
    "    bag_of_words = vec.fit_transform(column)\n",
    "    sum_words = bag_of_words.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:top_nu_of_words]\n",
    "\n",
    "\n",
    "#Top 15-word frequency for restaurant types\n",
    "lst = get_top_words(df['Type'], 15, (2,2))\n",
    "\n",
    "df_words = pd.DataFrame(lst, columns=['Word','Count'])\n",
    "plt.figure(figsize=(7,6))\n",
    "sns.barplot(data=df_words, x='Count', y='Word')\n",
    "plt.title('Word Couple Frequency for Restaurant Types');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-based recommender system using TF-IDF Matrix (Term Frequency — Inverse Document Frequency Matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF method is used to quantify words and compute weights for them. \n",
    "In other words, representing each word (or couples of words etc.) with a number in order to use mathematics in our recommender system. \n",
    "Put simply, the higher the TF*IDF score (weight), the rarer and more important the term, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('Name', inplace=True)\n",
    "indices = pd.Series(df.index)\n",
    "\n",
    "# Creating tf-idf matrix\n",
    "tfidf = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), min_df=0, stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(df['Comments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the tfidf_matrix is the matrix containing each word and its TF-IDF score with regard to each document, or item in this case. \n",
    "Also, stop words are simply words that add no significant value to our system, like ‘an’, ‘is’, ‘the’, and hence are ignored by the system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine similarity is a metric used to determine how similar the documents are irrespective of their size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's build the recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(name, cosine_similarities = cosine_similarities):\n",
    "   \n",
    "    recommend_restaurant = []\n",
    "    \n",
    "    # Find the index of the restaurant entered\n",
    "    idx = indices[indices == name].index[0]\n",
    "    \n",
    "    # Find the restaurants with a similar cosine-sim value and order them from bigges number\n",
    "    score_series = pd.Series(cosine_similarities[idx]).sort_values(ascending=False)\n",
    "    \n",
    "    # Extract top 30 restaurant indexes with a similar cosine-sim value\n",
    "    top30_indexes = list(score_series.iloc[0:31].index)\n",
    "    \n",
    "    # Names of the top 30 restaurants\n",
    "    for each in top30_indexes:\n",
    "        recommend_restaurant.append(list(df.index)[each])\n",
    "    \n",
    "    # Creating the new data set to show similar restaurants\n",
    "    df_new = pd.DataFrame(columns=['Type', 'Mean Rating', 'Price_Range'])\n",
    "    \n",
    "    # Create the top 30 similar restaurants with some of their columns\n",
    "    for each in recommend_restaurant:\n",
    "        df_new = df_new.append(pd.DataFrame(df[['Type','Mean Rating', 'Price_Range']][df.index == each].sample()))\n",
    "    \n",
    "    # Drop the same named restaurants and sort only the top 10 by the highest rating\n",
    "    df_new = df_new.drop_duplicates(subset=['Type','Mean Rating', 'Price_Range'], keep=False)\n",
    "    df_new = df_new.sort_values(by='Mean Rating', ascending=False).head(10)\n",
    "    \n",
    "    print('TOP %s RESTAURANTS LIKE %s WITH SIMILAR REVIEWS: ' % (str(len(df_new)), name))\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's test the recommendation system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I picked The Clam Bar since I was thinking about going out for seafood when I did this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['The Clam Bar'][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the recommendation system\n",
    "recommend('The Clam Bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:\n",
    "\n",
    "1. https://medium.com/mlearning-ai/restaurant-recommendation-system-based-on-the-content-in-reviews-dfc3351004db\n",
    "2. https://thecleverprogrammer.com/2022/07/26/restaurant-recommendation-system-using-python/\n",
    "3. https://towardsdatascience.com/how-to-build-a-restaurant-recommendation-system-using-latent-factor-collaborative-filtering-ffe08dd57dca"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
